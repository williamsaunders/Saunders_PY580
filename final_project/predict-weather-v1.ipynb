{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "520a53ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n",
    "\n",
    "from matplotlib_inline import backend_inline\n",
    "backend_inline.set_matplotlib_formats('retina')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45974c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import os,sys\n",
    "import numpy as np\n",
    "import torch # pytorch package, allows using GPUs\n",
    "# fix seed\n",
    "seed=17\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "from datetime import datetime\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import psutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d8a9771",
   "metadata": {},
   "outputs": [],
   "source": [
    "mem_usage = psutil.virtual_memory()\n",
    "mem_usage_start = mem_usage.used"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b40747",
   "metadata": {},
   "source": [
    "# Step 1. Identify data and info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d3b4eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_file_info = pd.DataFrame({'filelist' : glob('data/tmax_train/*.h5')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6789c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_file_info['num'] = [int(file.split('/')[2].split('_')[-1].split('.')[0]) for file in X_train_file_info['filelist']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ecd23896",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_file_info = X_train_file_info.sort_values('num')\n",
    "X_train_file_info.index = range(len(X_train_file_info))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "523e5c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_info = np.load('data/tmax_train/tmax_X_train_info.npz').get('arr_0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64575373",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.load('data/tmax_train/tmax_y_train.npz', allow_pickle=True).get('arr_0')\n",
    "y_train = np.nan_to_num(y_train.astype(float), nan=-8888)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "683d1c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Free: 2.1%\n",
      "Total: 251.65G\n",
      "Used: 4.34G\n",
      "Used - Start: 0.21G\n"
     ]
    }
   ],
   "source": [
    "mem_usage = psutil.virtual_memory()\n",
    "\n",
    "print(f\"Free: {mem_usage.percent}%\")\n",
    "print(f\"Total: {mem_usage.total/(1024**3):.2f}G\")\n",
    "print(f\"Used: {mem_usage.used/(1024**3):.2f}G\")\n",
    "print(f\"Used - Start: {(mem_usage.used - mem_usage_start)/(1024**3):.2f}G\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa51ca0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_file_info = pd.DataFrame({'filelist' : glob('data/tmax_val/*.h5')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c661d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_file_info['num'] = [int(file.split('/')[2].split('_')[-1].split('.')[0]) for file in X_val_file_info['filelist']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b0c46f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_file_info = X_val_file_info.sort_values('num')\n",
    "X_val_file_info.index = range(len(X_val_file_info))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d6bfc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_info = np.load('data/tmax_val/tmax_X_val_info.npz').get('arr_0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e550eb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val = np.load('data/tmax_val/tmax_y_val.npz', allow_pickle=True).get('arr_0')\n",
    "y_val = np.nan_to_num(y_val.astype(float), nan=-8888)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "65455ea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Free: 2.1%\n",
      "Total: 251.65G\n",
      "Used: 4.34G\n",
      "Used - Start: 0.21G\n"
     ]
    }
   ],
   "source": [
    "mem_usage = psutil.virtual_memory()\n",
    "\n",
    "print(f\"Free: {mem_usage.percent}%\")\n",
    "print(f\"Total: {mem_usage.total/(1024**3):.2f}G\")\n",
    "print(f\"Used: {mem_usage.used/(1024**3):.2f}G\")\n",
    "print(f\"Used - Start: {(mem_usage.used - mem_usage_start)/(1024**3):.2f}G\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61de7839",
   "metadata": {},
   "source": [
    "# Step 2. Initialize the dataset with a data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "67b1c3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class WeatherDataset(Dataset):\n",
    "    def __init__(self, data_path, y_data, batch_size=1000):\n",
    "        super().__init__()\n",
    "        with h5py.File(data_path, 'r') as f:\n",
    "            self.data_X = np.array(f['data'])\n",
    "        self.data_y = np.array(np.split(y_data, len(self.data_X)//batch_size))\n",
    "        self.data_X = np.array(np.split(self.data_X, len(self.data_X)//batch_size))\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data_X[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_X)\n",
    "\n",
    "def load_data(dataset_path, y_data, i):\n",
    "    # define dataset path\n",
    "    \n",
    "    # create dataset object\n",
    "    batch_size = 1000\n",
    "    dataset = WeatherDataset(dataset_path[i], y_data[i*1000:i*1000+1000], batch_size=batch_size)\n",
    "\n",
    "    # create data loader object\n",
    "    data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "    return data_loader"
   ]
  },
  {
   "cell_type": "raw",
   "id": "91005d53",
   "metadata": {},
   "source": [
    "data_chunk = load_data(X_train_file_info['filelist'].tolist(), y_train, 0)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9b182c58",
   "metadata": {},
   "source": [
    "data_chunk.dataset.data_X.shape"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9bc5a2a4",
   "metadata": {},
   "source": [
    "data_chunk.dataset.data_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b499e359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Free: 2.1%\n",
      "Total: 251.65G\n",
      "Used: 4.33G\n",
      "Used - Start: 0.21G\n"
     ]
    }
   ],
   "source": [
    "mem_usage = psutil.virtual_memory()\n",
    "\n",
    "print(f\"Free: {mem_usage.percent}%\")\n",
    "print(f\"Total: {mem_usage.total/(1024**3):.2f}G\")\n",
    "print(f\"Used: {mem_usage.used/(1024**3):.2f}G\")\n",
    "print(f\"Used - Start: {(mem_usage.used - mem_usage_start)/(1024**3):.2f}G\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434a560b",
   "metadata": {},
   "source": [
    "# Step 3. Design the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a56b8e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class PeriodicConv3d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1):\n",
    "        super(PeriodicConv3d, self).__init__()\n",
    "        self.conv = nn.Conv3d(in_channels, out_channels, kernel_size, stride=stride, padding=0, dilation=dilation, groups=groups)\n",
    "\n",
    "        # Set the padding to 0 since we will add the padding manually using F.pad\n",
    "        self.conv.padding = (0, 0, 0)\n",
    "\n",
    "        # Save the kernel size and stride\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "\n",
    "        # Compute the padding size\n",
    "        self.padding_size = ((kernel_size[0]-1)//2, (kernel_size[1]-1)//2, (kernel_size[2]-1)//2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Pad the input tensor with the last slice of the tensor along each dimension\n",
    "        x = F.pad(x, (self.padding_size[2], self.padding_size[2], self.padding_size[1], self.padding_size[1], self.padding_size[0], self.padding_size[0]), mode='circular')\n",
    "\n",
    "        # Perform the convolution\n",
    "        x = self.conv(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "9f468b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, batch_size=100, n_conv=2, out_channels=16, kernel_size=(5, 30, 5), stride=3, padding=5, \\\n",
    "                 fc_features=1024):\n",
    "        \"\"\"\n",
    "        batch_size is the batch size \n",
    "        n_conv is the number of convolutions to do\n",
    "        out_channels is the number of output channels from the first convolution. The second and onward double each time. \n",
    "        kernel_size is the shape of the convolution kernel\n",
    "        stride is the stride\n",
    "        fc_features is the number of features for the fully-connected layer\n",
    "        \"\"\"\n",
    "        \n",
    "        super(Model, self).__init__()\n",
    "        \n",
    "        # 3D convolutional layers\n",
    "        if padding == 'circular':\n",
    "            self.conv1 = PeriodicConv3d(in_channels=10, out_channels=out_channels, kernel_size=kernel_size, stride=stride, \\\n",
    "                                        padding=padding)\n",
    "            self.conv2 = PeriodicConv3d(in_channels=out_channels, out_channels=out_channels*2, kernel_size=kernel_size, \\\n",
    "                                        stride=stride, padding=padding)\n",
    "        else:\n",
    "            self.conv1 = nn.Conv3d(in_channels=10, out_channels=out_channels, kernel_size=kernel_size, stride=stride, \\\n",
    "                                   padding=padding)\n",
    "            self.conv2 = nn.Conv3d(in_channels=out_channels, out_channels=out_channels*2, kernel_size=kernel_size, \\\n",
    "                                   stride=stride, padding=padding)\n",
    "        \n",
    "        # Batch normalization layers\n",
    "        self.bn1 = nn.BatchNorm3d(num_features=out_channels)\n",
    "        self.bn2 = nn.BatchNorm3d(num_features=out_channels*2)\n",
    "        \n",
    "        # Max pooling layer\n",
    "        self.pool = nn.MaxPool3d(kernel_size=(1,2,2), stride=(1,2,2))\n",
    "        \n",
    "        # Fully connected layers\n",
    "        if padding == 'circular':\n",
    "            num_features = np.array([\\\n",
    "                1, \\\n",
    "                out_channels*n_conv, \\\n",
    "                (( ((11+self.conv1.padding_size[0]*2 - kernel_size[0])//stride + 1) +self.conv1.padding_size[0]*2 - kernel_size[0] )//stride + 1),\\\n",
    "                (( ((365+self.conv1.padding_size[1]*2 - kernel_size[1])//stride + 1)//2 +self.conv1.padding_size[1]*2 - kernel_size[1] )//stride + 1)//2,\\\n",
    "                (( ((batch_size+self.conv1.padding_size[2]*2 - kernel_size[2])//stride + 1)//2 +self.conv1.padding_size[2]*2 - kernel_size[2] )//stride + 1)//2,\\\n",
    "                                    ]).astype(int)\n",
    "        else:\n",
    "            num_features = np.array([\\\n",
    "                1, \\\n",
    "                out_channels*n_conv, \\\n",
    "                (( ((11+padding*2 - kernel_size[0])//stride + 1) +padding*2 - kernel_size[0] )//stride + 1),\\\n",
    "                (( ((365+padding*2 - kernel_size[1])//stride + 1)//2 +padding*2 - kernel_size[1] )//stride + 1)//2,\\\n",
    "                (( ((batch_size+padding*2 - kernel_size[2])//stride + 1)//2 +padding*2 - kernel_size[2] )//stride + 1)//2,\\\n",
    "                                    ]).astype(int)\n",
    "        #print('----', num_features, np.prod(num_features))\n",
    "        self.fc1 = nn.Linear(in_features=np.prod(num_features), out_features=fc_features) #32*5*182*128, 32*11*91*250\n",
    "        self.fc2 = nn.Linear(in_features=fc_features, out_features=7*batch_size)\n",
    "        \n",
    "        # Dropout layer\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "        \n",
    "        # ReLU activation function\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x, batch_size):\n",
    "        # Input shape: (batch_size=400000, channels=10, depth=11, height=365, width=1)\n",
    "        \n",
    "        # First convolutional block\n",
    "        #print(x.shape)\n",
    "        # Perform the convolution\n",
    "        x = self.conv1(x)\n",
    "        #print(x.shape)\n",
    "        x = self.bn1(x)\n",
    "        #print(x.shape)\n",
    "        x = self.relu(x)\n",
    "        #print(x.shape)\n",
    "        x = self.pool(x)\n",
    "        #print(x.shape)\n",
    "        \n",
    "        # Second convolutional block\n",
    "        x = self.conv2(x)\n",
    "        #print(x.shape)\n",
    "        x = self.bn2(x)\n",
    "        #print(x.shape)\n",
    "        x = self.relu(x)\n",
    "        #print(x.shape)\n",
    "        x = self.pool(x)\n",
    "        #print(x.shape)\n",
    "        \n",
    "        # Flatten\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        #print(x.shape)\n",
    "        \n",
    "        # Fully connected layers with dropout\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        # Output shape: (batch_size=400000, num_classes=10)\n",
    "        return x.reshape((1, 7, batch_size))\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "80754d01",
   "metadata": {},
   "source": [
    "11 : (( ((11+padding*2 - kernel_size[0])//stride + 1) +padding*2 - kernel_size[0] )//stride + 1)\n",
    "365 : (( ((365+padding*2 - kernel_size[1])//stride + 1)//2 +padding*2 - kernel_size[1] )//stride + 1)//2\n",
    "batch_size : (( ((batch_size+padding*2 - kernel_size[2])//stride + 1)//2 +padding*2 - kernel_size[2] )//stride + 1)//2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "916b9a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(output, labels):\n",
    "    \"A function that determines how close the outputs are to the real data\"\n",
    "    \"Report the total number within 5 and with 10 degrees celsius.\"\n",
    "    #print(output.shape)\n",
    "    #print(labels.shape)\n",
    "    \n",
    "    #rmse = torch.sqrt(torch.sum(labels - output)**2 / labels.size()[0])\n",
    "    within10 = torch.count_nonzero(torch.abs(labels - output) <= 100)\n",
    "    within5 = torch.count_nonzero(torch.abs(labels - output) <= 50)\n",
    "    \n",
    "    return np.array([within5.cpu(), within10.cpu()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "d321052b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(predictions, labels):\n",
    "    loss = torch.pow(torch.abs(predictions - labels), 0.75)\n",
    "    loss = torch.mean(loss)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "027d27a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch.optim as optim\n",
    "\n",
    "def train(model, train_data, val_data, batch_size=100, num_epochs=10, loss_function='l1', test_mode=False, out=False):\n",
    "    # loss function can be `l1` or `custom` for now\n",
    "    # test_mode uses only 10 files for each, off by default\n",
    "    # out returns the statistics, off by default\n",
    "    # Set device to GPU if available, else CPU\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    \n",
    "    # Define loss function and optimizer\n",
    "    #criterion = nn.CrossEntropyLoss()\n",
    "    #criterion = nn.MSELoss()\n",
    "    if loss_function == 'l1':\n",
    "        criterion = nn.L1Loss(reduction='sum')\n",
    "    elif loss_function == 'custom':\n",
    "        criterion = custom_loss\n",
    "    else:\n",
    "        print('NO LOSS FUNCTION CHOSEN, BAD, BAD!')\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        \n",
    "        # loop over each file within the big dataset\n",
    "        # FOR NOW THIS IS GOING TO BE HARD-CODED AND I NEED TO ADJUST IT LATER\n",
    "        # there are 462 files, but let's not use the last one since it'll be a different shape, so 461 to use.\n",
    "        # in each epoch, select a random order to train them in \n",
    "        file_order = np.arange(0, 461)\n",
    "        if test_mode:\n",
    "            file_order = np.arange(0, 10)\n",
    "        np.random.shuffle(file_order)\n",
    "        \n",
    "        for file_i, file_num in enumerate(file_order):\n",
    "            print('Training on file', file_i+1, '/', len(file_order), '\\r', end='')\n",
    "            train_data = train_loader(file_i)\n",
    "            \n",
    "            num_batches = train_data.dataset.data_X.shape[1]//batch_size\n",
    "            # iterate over the batches\n",
    "            for batch_i in range(num_batches):\n",
    "                #print('batch', batch_i+1, '/', train_data.dataset.data_X.shape[1]//batch_size, '\\r', end='')\n",
    "                inputs = torch.Tensor(train_data.dataset.data_X[:, batch_i*batch_size:(batch_i+1)*batch_size, :, :, :]\\\n",
    "                                      .astype('int64')).reshape(1, 10, 11, 365, batch_size)\n",
    "                labels = torch.Tensor(train_data.dataset.data_y[:, batch_i*batch_size:(batch_i+1)*batch_size, :]\\\n",
    "                                      .astype('int64')).reshape(1, 7, batch_size)\n",
    "\n",
    "                # Move data to device\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                #  pass\n",
    "                outputs = model(inputs, batch_size)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                # Backward pass and optimization\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                # Track training loss and accuracy\n",
    "                train_loss += loss.item() * inputs.size(0)\n",
    "                #_, predicted = torch.max(outputs.data, 1)\n",
    "                predicted = outputs\n",
    "                train_correct += accuracy(predicted, labels)\n",
    "                \n",
    "                #del inputs, labels, outputs, loss\n",
    "                #gc.collect()\n",
    "                #torch.cuda.empty_cache()\n",
    "\n",
    "        # Calculate average training loss and accuracy\n",
    "        train_loss /= len(train_data.dataset.data_X)\n",
    "        #train_accuracy = 100. * train_correct / len(train_data.dataset)\n",
    "        train_accuracy5 = 100*train_correct[0]/(predicted.numel()*num_batches*len(file_order))\n",
    "        train_accuracy10 = 100*train_correct[1]/(predicted.numel()*num_batches*len(file_order))\n",
    "        \n",
    "        # Evaluate on validation set\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "\n",
    "        # Loop through each validation file\n",
    "        val_file_order = np.arange(0, 46)\n",
    "        if test_mode:\n",
    "            val_file_order = np.arange(0, 10)\n",
    "        np.random.shuffle(val_file_order)\n",
    "        for file_i, file_num in enumerate(val_file_order):\n",
    "            print('Validating on file', file_i+1, '/', len(val_file_order), '\\r', end='')\n",
    "            val_data = val_loader(file_i)\n",
    "        \n",
    "            # Disable gradient computation\n",
    "            with torch.no_grad():\n",
    "\n",
    "                # iterate over the batches for the validation set \n",
    "                for batch_i in range(val_data.dataset.data_X.shape[1]//batch_size):\n",
    "                    #print('batch', batch_i+1, '/', val_data.dataset.data_X.shape[1]//batch_size, '\\r', end='')\n",
    "                    inputs = torch.Tensor(val_data.dataset.data_X[:, batch_i*batch_size:(batch_i+1)*batch_size, :, :, :]\\\n",
    "                                          .astype('int64')).reshape(1, 10, 11, 365, batch_size)\n",
    "                    labels = torch.Tensor(val_data.dataset.data_y[:, batch_i*batch_size:(batch_i+1)*batch_size, :]\\\n",
    "                                          .astype('int64')).reshape(1, 7, batch_size)\n",
    "                    \n",
    "                    # Move data to device\n",
    "                    inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                    #  pass\n",
    "                    outputs = model(inputs, batch_size)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # Track validation loss and accuracy\n",
    "                    val_loss += loss.item() * inputs.size(0)\n",
    "                    #_, predicted = torch.max(outputs.data, 1)\n",
    "                    predicted = outputs\n",
    "                    val_correct += accuracy(predicted, labels)\n",
    "                    \n",
    "                    #del inputs, labels, outputs, loss\n",
    "                    #gc.collect()\n",
    "                    #torch.cuda.empty_cache()\n",
    "            \n",
    "        # Calculate average validation loss and accuracy\n",
    "        val_loss /= len(val_data.dataset.data_X)\n",
    "        #val_accuracy = 100. * val_correct / len(val_data.dataset)\n",
    "        val_accuracy5 = 100*val_correct[0]/(predicted.numel()*num_batches*len(val_file_order))\n",
    "        val_accuracy10 = 100*val_correct[1]/(predicted.numel()*num_batches*len(val_file_order))\n",
    "        \n",
    "        # Print epoch statistics\n",
    "        print(\"Epoch [{}/{}] Train Loss: {:.2e}, Train Acc10: {:.1f}%, Train Acc5: {:.1f}% | \\\n",
    "Val Loss: {:.2e}, Val Acc10: {:.1f}%, Val Acc5: {:.1f}%\"\n",
    "              .format(epoch+1, num_epochs, train_loss, train_accuracy10, train_accuracy5, \\\n",
    "                      val_loss, val_accuracy10, val_accuracy5))\n",
    "\n",
    "    if out:\n",
    "        return (train_loss, train_accuracy10, train_accuracy5, val_loss, val_accuracy10, val_accuracy5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "4c42b3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loader(i):\n",
    "    return load_data(X_train_file_info['filelist'].tolist(), y_train, i)\n",
    "\n",
    "def val_loader(i):\n",
    "    return load_data(X_val_file_info['filelist'].tolist(), y_val, i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149eaf4c",
   "metadata": {},
   "source": [
    "# Step 4. Run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "b52c46d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    del(model)\n",
    "except NameError:\n",
    "    pass\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "73079ea2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = Model(batch_size=25, n_conv=2, out_channels=64, kernel_size=(5, 30, 5), stride=2, padding=1, \\\n",
    "              fc_features=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "9dd5c4e4",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100] Train Loss: 3.54e+03, Train Acc10: 73.5%, Train Acc5: 42.8% | Val Loss: 7.52e+03, Val Acc10: 61.2%, Val Acc5: 34.4%\n",
      "Epoch [2/100] Train Loss: 3.20e+03, Train Acc10: 82.9%, Train Acc5: 51.5% | Val Loss: 7.34e+03, Val Acc10: 66.1%, Val Acc5: 38.6%\n",
      "Training on file 2 / 10 \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/scratch/7627609.1.p100/ipykernel_12135/2703417745.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'custom'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/scratch/7627609.1.p100/ipykernel_12135/1201456814.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_data, val_data, batch_size, num_epochs, loss_function, test_mode, out)\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mbatch_i\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m                 \u001b[0;31m#print('batch', batch_i+1, '/', train_data.dataset.data_X.shape[1]//batch_size, '\\r', end='')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m                 inputs = torch.Tensor(train_data.dataset.data_X[:, batch_i*batch_size:(batch_i+1)*batch_size, :, :, :]\\\n\u001b[0m\u001b[1;32m     47\u001b[0m                                       .astype('int64')).reshape(1, 10, 11, 365, batch_size)\n\u001b[1;32m     48\u001b[0m                 labels = torch.Tensor(train_data.dataset.data_y[:, batch_i*batch_size:(batch_i+1)*batch_size, :]\\\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(model, train_loader, val_loader, num_epochs=100, batch_size=25, test_mode=True, loss_function='custom')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ecddb63",
   "metadata": {},
   "source": [
    "# Step 5. Tune the hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "26468549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let stride = 2\n",
    "kernel_size_list = [\n",
    "[3, 10, 3],\n",
    "[3, 30, 3],\n",
    "[3, 50, 3],\n",
    "\n",
    "[5, 10, 5],\n",
    "[5, 30, 5],\n",
    "[5, 50, 5]]\n",
    "out_channels_list = [32]\n",
    "fc_features_list = [1024, 2048]\n",
    "padding_list = ['circular']\n",
    "loss_function_list = ['l1', 'custom']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "7829bb42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "6 * 1 * 2 * 1 * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "8de92ab6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "kernel_size : [3, 10, 3] | out_channels : 32  | fc_features : 1024 | loss func : l1\n",
      "Epoch [1/10] Train Loss: 1.18e+07, Train Acc10: 82.2%, Train Acc5: 52.1% | Val Loss: 8.16e+07, Val Acc10: 69.7%, Val Acc5: 42.1%\n",
      "Epoch [2/10] Train Loss: 1.11e+07, Train Acc10: 88.9%, Train Acc5: 58.7% | Val Loss: 8.16e+07, Val Acc10: 69.5%, Val Acc5: 41.1%\n",
      "Epoch [3/10] Train Loss: 1.12e+07, Train Acc10: 88.0%, Train Acc5: 57.0% | Val Loss: 8.16e+07, Val Acc10: 70.8%, Val Acc5: 43.3%\n",
      "Epoch [4/10] Train Loss: 1.12e+07, Train Acc10: 88.1%, Train Acc5: 57.4% | Val Loss: 8.20e+07, Val Acc10: 62.7%, Val Acc5: 33.7%\n",
      "Epoch [5/10] Train Loss: 1.10e+07, Train Acc10: 89.0%, Train Acc5: 59.2% | Val Loss: 8.16e+07, Val Acc10: 69.2%, Val Acc5: 40.7%\n",
      "Epoch [6/10] Train Loss: 1.09e+07, Train Acc10: 90.2%, Train Acc5: 60.8% | Val Loss: 8.16e+07, Val Acc10: 69.2%, Val Acc5: 40.9%\n",
      "Epoch [7/10] Train Loss: 1.09e+07, Train Acc10: 90.4%, Train Acc5: 61.5% | Val Loss: 8.15e+07, Val Acc10: 69.4%, Val Acc5: 41.0%\n",
      "Epoch [8/10] Train Loss: 1.09e+07, Train Acc10: 90.2%, Train Acc5: 60.8% | Val Loss: 8.16e+07, Val Acc10: 68.3%, Val Acc5: 39.9%\n",
      "Epoch [9/10] Train Loss: 1.09e+07, Train Acc10: 90.8%, Train Acc5: 61.9% | Val Loss: 8.16e+07, Val Acc10: 68.4%, Val Acc5: 40.5%\n",
      "Epoch [10/10] Train Loss: 1.08e+07, Train Acc10: 91.3%, Train Acc5: 62.6% | Val Loss: 8.16e+07, Val Acc10: 69.4%, Val Acc5: 41.8%\n",
      "\n",
      "kernel_size : [3, 10, 3] | out_channels : 32  | fc_features : 1024 | loss func : custom\n",
      "Epoch [1/10] Train Loss: 3.55e+03, Train Acc10: 72.7%, Train Acc5: 43.1% | Val Loss: 7.37e+03, Val Acc10: 65.5%, Val Acc5: 38.1%\n",
      "Epoch [2/10] Train Loss: 3.19e+03, Train Acc10: 83.6%, Train Acc5: 51.6% | Val Loss: 7.32e+03, Val Acc10: 66.9%, Val Acc5: 39.8%\n",
      "Epoch [3/10] Train Loss: 3.14e+03, Train Acc10: 84.9%, Train Acc5: 53.1% | Val Loss: 7.35e+03, Val Acc10: 66.4%, Val Acc5: 38.2%\n",
      "Epoch [4/10] Train Loss: 3.09e+03, Train Acc10: 86.1%, Train Acc5: 55.3% | Val Loss: 7.27e+03, Val Acc10: 68.7%, Val Acc5: 41.3%\n",
      "Epoch [5/10] Train Loss: 3.03e+03, Train Acc10: 87.6%, Train Acc5: 57.2% | Val Loss: 7.26e+03, Val Acc10: 68.8%, Val Acc5: 40.8%\n",
      "Epoch [6/10] Train Loss: 3.03e+03, Train Acc10: 88.0%, Train Acc5: 57.1% | Val Loss: 7.25e+03, Val Acc10: 69.2%, Val Acc5: 41.6%\n",
      "Epoch [7/10] Train Loss: 3.05e+03, Train Acc10: 87.2%, Train Acc5: 56.7% | Val Loss: 7.26e+03, Val Acc10: 68.9%, Val Acc5: 40.8%\n",
      "Epoch [8/10] Train Loss: 3.00e+03, Train Acc10: 88.6%, Train Acc5: 57.8% | Val Loss: 7.26e+03, Val Acc10: 69.0%, Val Acc5: 41.1%\n",
      "Epoch [9/10] Train Loss: 3.00e+03, Train Acc10: 88.2%, Train Acc5: 58.6% | Val Loss: 7.27e+03, Val Acc10: 68.6%, Val Acc5: 40.9%\n",
      "Epoch [10/10] Train Loss: 3.00e+03, Train Acc10: 88.3%, Train Acc5: 58.7% | Val Loss: 7.29e+03, Val Acc10: 68.1%, Val Acc5: 40.1%\n",
      "\n",
      "kernel_size : [3, 10, 3] | out_channels : 32  | fc_features : 2048 | loss func : l1\n",
      "Epoch [1/10] Train Loss: 1.18e+07, Train Acc10: 82.4%, Train Acc5: 52.0% | Val Loss: 8.17e+07, Val Acc10: 68.8%, Val Acc5: 41.3%\n",
      "Epoch [2/10] Train Loss: 1.13e+07, Train Acc10: 87.1%, Train Acc5: 56.0% | Val Loss: 8.16e+07, Val Acc10: 69.6%, Val Acc5: 41.7%\n",
      "Epoch [3/10] Train Loss: 1.12e+07, Train Acc10: 87.8%, Train Acc5: 57.1% | Val Loss: 8.16e+07, Val Acc10: 70.1%, Val Acc5: 42.1%\n",
      "Epoch [4/10] Train Loss: 1.11e+07, Train Acc10: 88.5%, Train Acc5: 57.6% | Val Loss: 8.16e+07, Val Acc10: 67.8%, Val Acc5: 39.5%\n",
      "Epoch [5/10] Train Loss: 1.10e+07, Train Acc10: 89.4%, Train Acc5: 59.6% | Val Loss: 8.16e+07, Val Acc10: 68.7%, Val Acc5: 40.4%\n",
      "Epoch [6/10] Train Loss: 1.10e+07, Train Acc10: 90.0%, Train Acc5: 59.9% | Val Loss: 8.15e+07, Val Acc10: 69.5%, Val Acc5: 41.6%\n",
      "Epoch [7/10] Train Loss: 1.09e+07, Train Acc10: 90.2%, Train Acc5: 60.9% | Val Loss: 8.16e+07, Val Acc10: 68.0%, Val Acc5: 39.8%\n",
      "Epoch [8/10] Train Loss: 1.09e+07, Train Acc10: 90.7%, Train Acc5: 61.8% | Val Loss: 8.15e+07, Val Acc10: 68.9%, Val Acc5: 41.1%\n",
      "Epoch [9/10] Train Loss: 1.09e+07, Train Acc10: 90.8%, Train Acc5: 61.8% | Val Loss: 8.15e+07, Val Acc10: 69.4%, Val Acc5: 41.9%\n",
      "Epoch [10/10] Train Loss: 1.09e+07, Train Acc10: 90.6%, Train Acc5: 61.9% | Val Loss: 8.16e+07, Val Acc10: 68.7%, Val Acc5: 40.9%\n",
      "\n",
      "kernel_size : [3, 10, 3] | out_channels : 32  | fc_features : 2048 | loss func : custom\n",
      "Epoch [1/10] Train Loss: 3.50e+03, Train Acc10: 74.5%, Train Acc5: 43.5% | Val Loss: 7.46e+03, Val Acc10: 62.5%, Val Acc5: 35.9%\n",
      "Epoch [2/10] Train Loss: 3.20e+03, Train Acc10: 83.2%, Train Acc5: 52.0% | Val Loss: 7.31e+03, Val Acc10: 67.0%, Val Acc5: 39.4%\n",
      "Epoch [3/10] Train Loss: 3.14e+03, Train Acc10: 84.5%, Train Acc5: 53.4% | Val Loss: 7.29e+03, Val Acc10: 68.2%, Val Acc5: 40.5%\n",
      "Epoch [4/10] Train Loss: 3.09e+03, Train Acc10: 86.2%, Train Acc5: 55.3% | Val Loss: 7.27e+03, Val Acc10: 68.4%, Val Acc5: 41.0%\n",
      "Epoch [5/10] Train Loss: 3.06e+03, Train Acc10: 86.7%, Train Acc5: 56.3% | Val Loss: 7.30e+03, Val Acc10: 67.6%, Val Acc5: 39.7%\n",
      "Epoch [6/10] Train Loss: 3.10e+03, Train Acc10: 85.8%, Train Acc5: 55.2% | Val Loss: 7.26e+03, Val Acc10: 68.6%, Val Acc5: 41.4%\n",
      "Epoch [7/10] Train Loss: 3.02e+03, Train Acc10: 88.1%, Train Acc5: 57.7% | Val Loss: 7.27e+03, Val Acc10: 68.5%, Val Acc5: 41.4%\n",
      "Epoch [8/10] Train Loss: 2.99e+03, Train Acc10: 88.5%, Train Acc5: 58.8% | Val Loss: 7.23e+03, Val Acc10: 69.4%, Val Acc5: 42.2%\n",
      "Epoch [9/10] Train Loss: 2.98e+03, Train Acc10: 88.9%, Train Acc5: 59.2% | Val Loss: 7.25e+03, Val Acc10: 69.0%, Val Acc5: 41.6%\n",
      "Epoch [10/10] Train Loss: 2.99e+03, Train Acc10: 88.8%, Train Acc5: 58.6% | Val Loss: 7.23e+03, Val Acc10: 69.7%, Val Acc5: 42.2%\n",
      "\n",
      "kernel_size : [3, 30, 3] | out_channels : 32  | fc_features : 1024 | loss func : l1\n",
      "Epoch [1/10] Train Loss: 1.19e+07, Train Acc10: 81.7%, Train Acc5: 52.0% | Val Loss: 8.16e+07, Val Acc10: 67.9%, Val Acc5: 40.0%\n",
      "Epoch [2/10] Train Loss: 1.11e+07, Train Acc10: 88.8%, Train Acc5: 58.3% | Val Loss: 8.16e+07, Val Acc10: 69.6%, Val Acc5: 42.4%\n",
      "Epoch [3/10] Train Loss: 1.11e+07, Train Acc10: 88.6%, Train Acc5: 58.1% | Val Loss: 8.16e+07, Val Acc10: 69.1%, Val Acc5: 41.2%\n",
      "Epoch [4/10] Train Loss: 1.10e+07, Train Acc10: 89.9%, Train Acc5: 60.3% | Val Loss: 8.15e+07, Val Acc10: 69.1%, Val Acc5: 41.1%\n",
      "Epoch [5/10] Train Loss: 1.09e+07, Train Acc10: 90.3%, Train Acc5: 60.8% | Val Loss: 8.15e+07, Val Acc10: 68.6%, Val Acc5: 40.3%\n",
      "Epoch [6/10] Train Loss: 1.09e+07, Train Acc10: 90.3%, Train Acc5: 61.1% | Val Loss: 8.15e+07, Val Acc10: 69.1%, Val Acc5: 41.0%\n",
      "Epoch [7/10] Train Loss: 1.09e+07, Train Acc10: 90.6%, Train Acc5: 61.7% | Val Loss: 8.16e+07, Val Acc10: 67.8%, Val Acc5: 39.3%\n",
      "Epoch [8/10] Train Loss: 1.09e+07, Train Acc10: 90.4%, Train Acc5: 61.6% | Val Loss: 8.16e+07, Val Acc10: 67.7%, Val Acc5: 39.4%\n",
      "Epoch [9/10] Train Loss: 1.09e+07, Train Acc10: 90.8%, Train Acc5: 62.2% | Val Loss: 8.15e+07, Val Acc10: 68.8%, Val Acc5: 40.8%\n",
      "Epoch [10/10] Train Loss: 1.08e+07, Train Acc10: 91.0%, Train Acc5: 62.5% | Val Loss: 8.15e+07, Val Acc10: 68.4%, Val Acc5: 40.5%\n",
      "\n",
      "kernel_size : [3, 30, 3] | out_channels : 32  | fc_features : 1024 | loss func : custom\n",
      "Epoch [1/10] Train Loss: 3.57e+03, Train Acc10: 72.3%, Train Acc5: 42.0% | Val Loss: 7.39e+03, Val Acc10: 64.7%, Val Acc5: 37.9%\n",
      "Epoch [2/10] Train Loss: 3.17e+03, Train Acc10: 83.9%, Train Acc5: 52.6% | Val Loss: 7.32e+03, Val Acc10: 66.5%, Val Acc5: 39.4%\n",
      "Epoch [3/10] Train Loss: 3.09e+03, Train Acc10: 86.0%, Train Acc5: 55.4% | Val Loss: 7.31e+03, Val Acc10: 67.3%, Val Acc5: 39.4%\n",
      "Epoch [4/10] Train Loss: 3.05e+03, Train Acc10: 87.3%, Train Acc5: 56.7% | Val Loss: 7.30e+03, Val Acc10: 67.4%, Val Acc5: 40.3%\n",
      "Epoch [5/10] Train Loss: 3.02e+03, Train Acc10: 87.7%, Train Acc5: 57.6% | Val Loss: 7.30e+03, Val Acc10: 67.6%, Val Acc5: 39.8%\n",
      "Epoch [6/10] Train Loss: 3.02e+03, Train Acc10: 88.1%, Train Acc5: 57.5% | Val Loss: 7.28e+03, Val Acc10: 68.0%, Val Acc5: 40.7%\n",
      "Epoch [7/10] Train Loss: 3.00e+03, Train Acc10: 88.4%, Train Acc5: 58.4% | Val Loss: 7.27e+03, Val Acc10: 68.4%, Val Acc5: 41.0%\n",
      "Epoch [8/10] Train Loss: 2.97e+03, Train Acc10: 89.0%, Train Acc5: 59.6% | Val Loss: 7.28e+03, Val Acc10: 67.8%, Val Acc5: 40.9%\n",
      "Epoch [9/10] Train Loss: 2.98e+03, Train Acc10: 89.2%, Train Acc5: 59.1% | Val Loss: 7.29e+03, Val Acc10: 67.9%, Val Acc5: 40.0%\n",
      "Epoch [10/10] Train Loss: 3.00e+03, Train Acc10: 88.3%, Train Acc5: 58.4% | Val Loss: 7.23e+03, Val Acc10: 69.4%, Val Acc5: 42.0%\n",
      "\n",
      "kernel_size : [3, 30, 3] | out_channels : 32  | fc_features : 2048 | loss func : l1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10] Train Loss: 1.18e+07, Train Acc10: 82.6%, Train Acc5: 52.3% | Val Loss: 8.16e+07, Val Acc10: 68.6%, Val Acc5: 41.4%\n",
      "Epoch [2/10] Train Loss: 1.11e+07, Train Acc10: 88.5%, Train Acc5: 58.8% | Val Loss: 8.15e+07, Val Acc10: 69.3%, Val Acc5: 41.8%\n",
      "Epoch [3/10] Train Loss: 1.12e+07, Train Acc10: 88.1%, Train Acc5: 57.4% | Val Loss: 8.15e+07, Val Acc10: 69.9%, Val Acc5: 42.1%\n",
      "Epoch [4/10] Train Loss: 1.11e+07, Train Acc10: 88.8%, Train Acc5: 58.4% | Val Loss: 8.16e+07, Val Acc10: 67.9%, Val Acc5: 39.3%\n",
      "Epoch [5/10] Train Loss: 1.11e+07, Train Acc10: 89.0%, Train Acc5: 58.6% | Val Loss: 8.16e+07, Val Acc10: 67.2%, Val Acc5: 38.0%\n",
      "Epoch [6/10] Train Loss: 1.10e+07, Train Acc10: 89.7%, Train Acc5: 60.2% | Val Loss: 8.15e+07, Val Acc10: 68.8%, Val Acc5: 39.8%\n",
      "Epoch [7/10] Train Loss: 1.09e+07, Train Acc10: 90.7%, Train Acc5: 61.9% | Val Loss: 8.15e+07, Val Acc10: 70.2%, Val Acc5: 41.7%\n",
      "Epoch [8/10] Train Loss: 1.08e+07, Train Acc10: 90.9%, Train Acc5: 62.3% | Val Loss: 8.15e+07, Val Acc10: 69.4%, Val Acc5: 40.7%\n",
      "Epoch [9/10] Train Loss: 1.09e+07, Train Acc10: 90.4%, Train Acc5: 61.7% | Val Loss: 8.14e+07, Val Acc10: 70.1%, Val Acc5: 41.8%\n",
      "Epoch [10/10] Train Loss: 1.09e+07, Train Acc10: 90.6%, Train Acc5: 61.7% | Val Loss: 8.15e+07, Val Acc10: 68.8%, Val Acc5: 39.8%\n",
      "\n",
      "kernel_size : [3, 30, 3] | out_channels : 32  | fc_features : 2048 | loss func : custom\n",
      "Epoch [1/10] Train Loss: 3.56e+03, Train Acc10: 72.5%, Train Acc5: 42.6% | Val Loss: 7.44e+03, Val Acc10: 63.6%, Val Acc5: 36.8%\n",
      "Epoch [2/10] Train Loss: 3.24e+03, Train Acc10: 82.0%, Train Acc5: 50.6% | Val Loss: 7.40e+03, Val Acc10: 64.1%, Val Acc5: 36.8%\n",
      "Epoch [3/10] Train Loss: 3.17e+03, Train Acc10: 83.7%, Train Acc5: 52.6% | Val Loss: 7.27e+03, Val Acc10: 68.5%, Val Acc5: 41.2%\n",
      "Epoch [4/10] Train Loss: 3.08e+03, Train Acc10: 86.3%, Train Acc5: 55.3% | Val Loss: 7.28e+03, Val Acc10: 67.9%, Val Acc5: 40.5%\n",
      "Epoch [5/10] Train Loss: 3.04e+03, Train Acc10: 87.6%, Train Acc5: 57.1% | Val Loss: 7.26e+03, Val Acc10: 68.5%, Val Acc5: 41.3%\n",
      "Epoch [6/10] Train Loss: 3.00e+03, Train Acc10: 88.2%, Train Acc5: 58.5% | Val Loss: 7.29e+03, Val Acc10: 67.8%, Val Acc5: 40.2%\n",
      "Epoch [7/10] Train Loss: 3.03e+03, Train Acc10: 87.7%, Train Acc5: 57.6% | Val Loss: 7.28e+03, Val Acc10: 68.0%, Val Acc5: 41.1%\n",
      "Epoch [8/10] Train Loss: 3.01e+03, Train Acc10: 88.3%, Train Acc5: 58.2% | Val Loss: 7.28e+03, Val Acc10: 67.9%, Val Acc5: 40.9%\n",
      "Epoch [9/10] Train Loss: 2.98e+03, Train Acc10: 88.9%, Train Acc5: 59.2% | Val Loss: 7.27e+03, Val Acc10: 68.2%, Val Acc5: 40.8%\n",
      "Epoch [10/10] Train Loss: 2.96e+03, Train Acc10: 89.1%, Train Acc5: 59.7% | Val Loss: 7.28e+03, Val Acc10: 68.1%, Val Acc5: 40.6%\n",
      "\n",
      "kernel_size : [3, 50, 3] | out_channels : 32  | fc_features : 1024 | loss func : l1\n",
      "Epoch [1/10] Train Loss: 1.20e+07, Train Acc10: 80.2%, Train Acc5: 51.1% | Val Loss: 8.16e+07, Val Acc10: 68.4%, Val Acc5: 40.5%\n",
      "Epoch [2/10] Train Loss: 1.10e+07, Train Acc10: 89.1%, Train Acc5: 59.0% | Val Loss: 8.16e+07, Val Acc10: 68.1%, Val Acc5: 40.3%\n",
      "Epoch [3/10] Train Loss: 1.10e+07, Train Acc10: 89.3%, Train Acc5: 59.6% | Val Loss: 8.16e+07, Val Acc10: 68.3%, Val Acc5: 39.7%\n",
      "Epoch [4/10] Train Loss: 1.10e+07, Train Acc10: 89.4%, Train Acc5: 59.8% | Val Loss: 8.16e+07, Val Acc10: 67.7%, Val Acc5: 39.2%\n",
      "Epoch [5/10] Train Loss: 1.10e+07, Train Acc10: 89.8%, Train Acc5: 60.4% | Val Loss: 8.15e+07, Val Acc10: 68.6%, Val Acc5: 40.4%\n",
      "Epoch [6/10] Train Loss: 1.09e+07, Train Acc10: 90.7%, Train Acc5: 61.6% | Val Loss: 8.15e+07, Val Acc10: 68.5%, Val Acc5: 40.1%\n",
      "Epoch [7/10] Train Loss: 1.09e+07, Train Acc10: 90.6%, Train Acc5: 61.8% | Val Loss: 8.16e+07, Val Acc10: 67.7%, Val Acc5: 39.2%\n",
      "Epoch [8/10] Train Loss: 1.09e+07, Train Acc10: 90.5%, Train Acc5: 61.9% | Val Loss: 8.16e+07, Val Acc10: 67.8%, Val Acc5: 39.4%\n",
      "Epoch [9/10] Train Loss: 1.08e+07, Train Acc10: 91.0%, Train Acc5: 62.5% | Val Loss: 8.15e+07, Val Acc10: 68.6%, Val Acc5: 40.5%\n",
      "Epoch [10/10] Train Loss: 1.08e+07, Train Acc10: 91.1%, Train Acc5: 62.7% | Val Loss: 8.16e+07, Val Acc10: 67.7%, Val Acc5: 39.5%\n",
      "\n",
      "kernel_size : [3, 50, 3] | out_channels : 32  | fc_features : 1024 | loss func : custom\n",
      "Epoch [1/10] Train Loss: 3.62e+03, Train Acc10: 70.9%, Train Acc5: 41.4% | Val Loss: 7.44e+03, Val Acc10: 63.2%, Val Acc5: 36.1%\n",
      "Epoch [2/10] Train Loss: 3.16e+03, Train Acc10: 84.3%, Train Acc5: 52.7% | Val Loss: 7.34e+03, Val Acc10: 65.9%, Val Acc5: 38.8%\n",
      "Epoch [3/10] Train Loss: 3.08e+03, Train Acc10: 86.3%, Train Acc5: 55.6% | Val Loss: 7.28e+03, Val Acc10: 67.8%, Val Acc5: 40.6%\n",
      "Epoch [4/10] Train Loss: 3.03e+03, Train Acc10: 87.5%, Train Acc5: 57.1% | Val Loss: 7.36e+03, Val Acc10: 65.8%, Val Acc5: 37.8%\n",
      "Epoch [5/10] Train Loss: 3.03e+03, Train Acc10: 87.7%, Train Acc5: 57.6% | Val Loss: 7.25e+03, Val Acc10: 68.7%, Val Acc5: 41.9%\n",
      "Epoch [6/10] Train Loss: 2.98e+03, Train Acc10: 88.7%, Train Acc5: 59.4% | Val Loss: 7.28e+03, Val Acc10: 67.8%, Val Acc5: 41.2%\n",
      "Epoch [7/10] Train Loss: 2.99e+03, Train Acc10: 88.5%, Train Acc5: 58.7% | Val Loss: 7.31e+03, Val Acc10: 67.1%, Val Acc5: 39.3%\n",
      "Epoch [8/10] Train Loss: 2.97e+03, Train Acc10: 88.9%, Train Acc5: 59.5% | Val Loss: 7.29e+03, Val Acc10: 67.5%, Val Acc5: 40.5%\n",
      "Epoch [9/10] Train Loss: 2.98e+03, Train Acc10: 88.8%, Train Acc5: 59.1% | Val Loss: 7.27e+03, Val Acc10: 68.4%, Val Acc5: 41.0%\n",
      "Epoch [10/10] Train Loss: 3.00e+03, Train Acc10: 88.4%, Train Acc5: 58.4% | Val Loss: 7.29e+03, Val Acc10: 67.4%, Val Acc5: 40.4%\n",
      "\n",
      "kernel_size : [3, 50, 3] | out_channels : 32  | fc_features : 2048 | loss func : l1\n",
      "Epoch [1/10] Train Loss: 1.18e+07, Train Acc10: 82.8%, Train Acc5: 52.9% | Val Loss: 8.17e+07, Val Acc10: 67.3%, Val Acc5: 40.0%\n",
      "Epoch [2/10] Train Loss: 1.11e+07, Train Acc10: 87.9%, Train Acc5: 57.9% | Val Loss: 8.16e+07, Val Acc10: 68.2%, Val Acc5: 40.1%\n",
      "Epoch [3/10] Train Loss: 1.11e+07, Train Acc10: 88.7%, Train Acc5: 58.6% | Val Loss: 8.17e+07, Val Acc10: 67.4%, Val Acc5: 39.5%\n",
      "Epoch [4/10] Train Loss: 1.10e+07, Train Acc10: 89.5%, Train Acc5: 59.3% | Val Loss: 8.15e+07, Val Acc10: 69.0%, Val Acc5: 41.0%\n",
      "Epoch [5/10] Train Loss: 1.10e+07, Train Acc10: 89.4%, Train Acc5: 59.6% | Val Loss: 8.16e+07, Val Acc10: 67.1%, Val Acc5: 38.8%\n",
      "Epoch [6/10] Train Loss: 1.09e+07, Train Acc10: 90.2%, Train Acc5: 60.7% | Val Loss: 8.15e+07, Val Acc10: 68.1%, Val Acc5: 39.9%\n",
      "Epoch [7/10] Train Loss: 1.09e+07, Train Acc10: 90.4%, Train Acc5: 60.8% | Val Loss: 8.15e+07, Val Acc10: 68.1%, Val Acc5: 40.3%\n",
      "Epoch [8/10] Train Loss: 1.09e+07, Train Acc10: 90.5%, Train Acc5: 61.2% | Val Loss: 8.15e+07, Val Acc10: 68.3%, Val Acc5: 40.1%\n",
      "Epoch [9/10] Train Loss: 1.09e+07, Train Acc10: 90.7%, Train Acc5: 61.9% | Val Loss: 8.15e+07, Val Acc10: 67.8%, Val Acc5: 39.6%\n",
      "Epoch [10/10] Train Loss: 1.08e+07, Train Acc10: 91.1%, Train Acc5: 62.7% | Val Loss: 8.15e+07, Val Acc10: 68.4%, Val Acc5: 40.3%\n",
      "\n",
      "kernel_size : [3, 50, 3] | out_channels : 32  | fc_features : 2048 | loss func : custom\n",
      "Epoch [1/10] Train Loss: 3.50e+03, Train Acc10: 74.5%, Train Acc5: 44.4% | Val Loss: 7.39e+03, Val Acc10: 64.6%, Val Acc5: 37.0%\n",
      "Epoch [2/10] Train Loss: 3.15e+03, Train Acc10: 84.4%, Train Acc5: 53.0% | Val Loss: 7.37e+03, Val Acc10: 65.2%, Val Acc5: 38.8%\n",
      "Epoch [3/10] Train Loss: 3.14e+03, Train Acc10: 84.9%, Train Acc5: 53.2% | Val Loss: 7.31e+03, Val Acc10: 67.1%, Val Acc5: 40.0%\n",
      "Epoch [4/10] Train Loss: 3.05e+03, Train Acc10: 87.3%, Train Acc5: 56.7% | Val Loss: 7.30e+03, Val Acc10: 67.0%, Val Acc5: 40.1%\n",
      "Epoch [5/10] Train Loss: 3.03e+03, Train Acc10: 87.5%, Train Acc5: 57.4% | Val Loss: 7.29e+03, Val Acc10: 67.6%, Val Acc5: 40.3%\n",
      "Epoch [6/10] Train Loss: 3.11e+03, Train Acc10: 85.2%, Train Acc5: 55.3% | Val Loss: 7.30e+03, Val Acc10: 67.1%, Val Acc5: 40.5%\n",
      "Epoch [7/10] Train Loss: 3.02e+03, Train Acc10: 87.8%, Train Acc5: 57.9% | Val Loss: 7.26e+03, Val Acc10: 68.4%, Val Acc5: 41.6%\n",
      "Epoch [8/10] Train Loss: 2.96e+03, Train Acc10: 89.1%, Train Acc5: 60.0% | Val Loss: 7.27e+03, Val Acc10: 68.2%, Val Acc5: 41.2%\n",
      "Epoch [9/10] Train Loss: 2.96e+03, Train Acc10: 89.3%, Train Acc5: 59.9% | Val Loss: 7.26e+03, Val Acc10: 68.4%, Val Acc5: 41.3%\n",
      "Epoch [10/10] Train Loss: 2.97e+03, Train Acc10: 89.0%, Train Acc5: 59.6% | Val Loss: 7.26e+03, Val Acc10: 68.3%, Val Acc5: 41.3%\n",
      "\n",
      "kernel_size : [5, 10, 5] | out_channels : 32  | fc_features : 1024 | loss func : l1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10] Train Loss: 1.19e+07, Train Acc10: 81.3%, Train Acc5: 51.0% | Val Loss: 8.16e+07, Val Acc10: 69.2%, Val Acc5: 41.2%\n",
      "Epoch [2/10] Train Loss: 1.11e+07, Train Acc10: 88.9%, Train Acc5: 58.5% | Val Loss: 8.15e+07, Val Acc10: 70.0%, Val Acc5: 42.1%\n",
      "Epoch [3/10] Train Loss: 1.11e+07, Train Acc10: 88.3%, Train Acc5: 57.9% | Val Loss: 8.16e+07, Val Acc10: 69.1%, Val Acc5: 41.2%\n",
      "Epoch [4/10] Train Loss: 1.11e+07, Train Acc10: 88.9%, Train Acc5: 58.9% | Val Loss: 8.15e+07, Val Acc10: 70.4%, Val Acc5: 42.4%\n",
      "Epoch [5/10] Train Loss: 1.10e+07, Train Acc10: 89.7%, Train Acc5: 60.3% | Val Loss: 8.15e+07, Val Acc10: 69.8%, Val Acc5: 41.5%\n",
      "Epoch [6/10] Train Loss: 1.09e+07, Train Acc10: 90.3%, Train Acc5: 61.0% | Val Loss: 8.16e+07, Val Acc10: 68.5%, Val Acc5: 39.9%\n",
      "Epoch [7/10] Train Loss: 1.09e+07, Train Acc10: 90.4%, Train Acc5: 61.1% | Val Loss: 8.15e+07, Val Acc10: 69.2%, Val Acc5: 40.6%\n",
      "Epoch [8/10] Train Loss: 1.09e+07, Train Acc10: 90.8%, Train Acc5: 62.2% | Val Loss: 8.15e+07, Val Acc10: 69.2%, Val Acc5: 40.2%\n",
      "Epoch [9/10] Train Loss: 1.09e+07, Train Acc10: 90.4%, Train Acc5: 61.4% | Val Loss: 8.15e+07, Val Acc10: 69.5%, Val Acc5: 40.6%\n",
      "Epoch [10/10] Train Loss: 1.09e+07, Train Acc10: 90.8%, Train Acc5: 61.8% | Val Loss: 8.15e+07, Val Acc10: 70.5%, Val Acc5: 42.0%\n",
      "\n",
      "kernel_size : [5, 10, 5] | out_channels : 32  | fc_features : 1024 | loss func : custom\n",
      "Epoch [1/10] Train Loss: 3.60e+03, Train Acc10: 71.5%, Train Acc5: 41.5% | Val Loss: 7.38e+03, Val Acc10: 65.1%, Val Acc5: 37.9%\n",
      "Epoch [2/10] Train Loss: 3.14e+03, Train Acc10: 84.7%, Train Acc5: 53.6% | Val Loss: 7.28e+03, Val Acc10: 68.2%, Val Acc5: 40.8%\n",
      "Epoch [3/10] Train Loss: 3.11e+03, Train Acc10: 85.7%, Train Acc5: 54.7% | Val Loss: 7.33e+03, Val Acc10: 66.7%, Val Acc5: 39.7%\n",
      "Epoch [4/10] Train Loss: 3.07e+03, Train Acc10: 86.6%, Train Acc5: 56.1% | Val Loss: 7.26e+03, Val Acc10: 69.0%, Val Acc5: 41.4%\n",
      "Epoch [5/10] Train Loss: 3.07e+03, Train Acc10: 86.5%, Train Acc5: 55.7% | Val Loss: 7.27e+03, Val Acc10: 68.6%, Val Acc5: 40.4%\n",
      "Epoch [6/10] Train Loss: 3.04e+03, Train Acc10: 87.6%, Train Acc5: 56.9% | Val Loss: 7.25e+03, Val Acc10: 68.8%, Val Acc5: 41.4%\n",
      "Epoch [7/10] Train Loss: 3.00e+03, Train Acc10: 88.5%, Train Acc5: 58.3% | Val Loss: 7.27e+03, Val Acc10: 68.4%, Val Acc5: 41.2%\n",
      "Epoch [8/10] Train Loss: 2.99e+03, Train Acc10: 88.6%, Train Acc5: 58.6% | Val Loss: 7.23e+03, Val Acc10: 69.5%, Val Acc5: 42.2%\n",
      "Epoch [9/10] Train Loss: 2.99e+03, Train Acc10: 88.6%, Train Acc5: 58.9% | Val Loss: 7.25e+03, Val Acc10: 69.2%, Val Acc5: 41.4%\n",
      "Epoch [10/10] Train Loss: 2.97e+03, Train Acc10: 88.9%, Train Acc5: 59.6% | Val Loss: 7.23e+03, Val Acc10: 69.5%, Val Acc5: 42.4%\n",
      "\n",
      "kernel_size : [5, 10, 5] | out_channels : 32  | fc_features : 2048 | loss func : l1\n",
      "Epoch [1/10] Train Loss: 1.18e+07, Train Acc10: 82.5%, Train Acc5: 51.8% | Val Loss: 8.17e+07, Val Acc10: 67.2%, Val Acc5: 38.6%\n",
      "Epoch [2/10] Train Loss: 1.13e+07, Train Acc10: 86.7%, Train Acc5: 55.5% | Val Loss: 8.16e+07, Val Acc10: 70.5%, Val Acc5: 42.8%\n",
      "Epoch [3/10] Train Loss: 1.12e+07, Train Acc10: 87.8%, Train Acc5: 57.0% | Val Loss: 8.16e+07, Val Acc10: 67.8%, Val Acc5: 39.4%\n",
      "Epoch [4/10] Train Loss: 1.11e+07, Train Acc10: 88.4%, Train Acc5: 58.0% | Val Loss: 8.15e+07, Val Acc10: 69.7%, Val Acc5: 41.5%\n",
      "Epoch [5/10] Train Loss: 1.11e+07, Train Acc10: 89.2%, Train Acc5: 59.1% | Val Loss: 8.16e+07, Val Acc10: 66.6%, Val Acc5: 38.0%\n",
      "Epoch [6/10] Train Loss: 1.10e+07, Train Acc10: 89.9%, Train Acc5: 59.9% | Val Loss: 8.15e+07, Val Acc10: 70.1%, Val Acc5: 42.1%\n",
      "Epoch [7/10] Train Loss: 1.09e+07, Train Acc10: 90.7%, Train Acc5: 61.7% | Val Loss: 8.15e+07, Val Acc10: 69.6%, Val Acc5: 41.6%\n",
      "Epoch [8/10] Train Loss: 1.10e+07, Train Acc10: 90.0%, Train Acc5: 60.5% | Val Loss: 8.14e+07, Val Acc10: 70.0%, Val Acc5: 42.2%\n",
      "Epoch [9/10] Train Loss: 1.09e+07, Train Acc10: 90.9%, Train Acc5: 62.3% | Val Loss: 8.15e+07, Val Acc10: 70.6%, Val Acc5: 42.8%\n",
      "Epoch [10/10] Train Loss: 1.08e+07, Train Acc10: 91.0%, Train Acc5: 62.5% | Val Loss: 8.14e+07, Val Acc10: 70.7%, Val Acc5: 43.5%\n",
      "\n",
      "kernel_size : [5, 10, 5] | out_channels : 32  | fc_features : 2048 | loss func : custom\n",
      "Epoch [1/10] Train Loss: 3.53e+03, Train Acc10: 73.5%, Train Acc5: 43.2% | Val Loss: 7.36e+03, Val Acc10: 65.8%, Val Acc5: 38.2%\n",
      "Epoch [2/10] Train Loss: 3.15e+03, Train Acc10: 84.4%, Train Acc5: 53.1% | Val Loss: 7.31e+03, Val Acc10: 67.3%, Val Acc5: 39.7%\n",
      "Epoch [3/10] Train Loss: 3.11e+03, Train Acc10: 85.4%, Train Acc5: 54.3% | Val Loss: 7.29e+03, Val Acc10: 67.5%, Val Acc5: 40.5%\n",
      "Epoch [4/10] Train Loss: 3.07e+03, Train Acc10: 86.7%, Train Acc5: 55.9% | Val Loss: 7.30e+03, Val Acc10: 67.5%, Val Acc5: 39.8%\n",
      "Epoch [5/10] Train Loss: 3.05e+03, Train Acc10: 87.0%, Train Acc5: 56.8% | Val Loss: 7.26e+03, Val Acc10: 68.7%, Val Acc5: 40.9%\n",
      "Epoch [6/10] Train Loss: 3.00e+03, Train Acc10: 88.4%, Train Acc5: 58.1% | Val Loss: 7.24e+03, Val Acc10: 69.3%, Val Acc5: 41.6%\n",
      "Epoch [7/10] Train Loss: 3.03e+03, Train Acc10: 88.1%, Train Acc5: 57.0% | Val Loss: 7.25e+03, Val Acc10: 68.8%, Val Acc5: 41.8%\n",
      "Epoch [8/10] Train Loss: 3.01e+03, Train Acc10: 87.9%, Train Acc5: 58.1% | Val Loss: 7.29e+03, Val Acc10: 67.5%, Val Acc5: 40.6%\n",
      "Epoch [9/10] Train Loss: 2.97e+03, Train Acc10: 88.9%, Train Acc5: 59.5% | Val Loss: 7.25e+03, Val Acc10: 68.8%, Val Acc5: 41.4%\n",
      "Epoch [10/10] Train Loss: 2.97e+03, Train Acc10: 89.1%, Train Acc5: 59.6% | Val Loss: 7.27e+03, Val Acc10: 68.2%, Val Acc5: 40.8%\n",
      "\n",
      "kernel_size : [5, 30, 5] | out_channels : 32  | fc_features : 1024 | loss func : l1\n",
      "Epoch [1/10] Train Loss: 1.21e+07, Train Acc10: 80.0%, Train Acc5: 50.6% | Val Loss: 8.19e+07, Val Acc10: 66.3%, Val Acc5: 39.8%\n",
      "Epoch [2/10] Train Loss: 1.12e+07, Train Acc10: 88.1%, Train Acc5: 57.8% | Val Loss: 8.16e+07, Val Acc10: 69.2%, Val Acc5: 41.8%\n",
      "Epoch [3/10] Train Loss: 1.11e+07, Train Acc10: 88.6%, Train Acc5: 58.7% | Val Loss: 8.16e+07, Val Acc10: 67.3%, Val Acc5: 38.9%\n",
      "Epoch [4/10] Train Loss: 1.10e+07, Train Acc10: 89.6%, Train Acc5: 60.2% | Val Loss: 8.17e+07, Val Acc10: 66.7%, Val Acc5: 38.5%\n",
      "Epoch [5/10] Train Loss: 1.10e+07, Train Acc10: 89.8%, Train Acc5: 60.6% | Val Loss: 8.16e+07, Val Acc10: 68.1%, Val Acc5: 39.9%\n",
      "Epoch [6/10] Train Loss: 1.10e+07, Train Acc10: 90.0%, Train Acc5: 60.6% | Val Loss: 8.16e+07, Val Acc10: 67.5%, Val Acc5: 39.2%\n",
      "Epoch [7/10] Train Loss: 1.09e+07, Train Acc10: 90.6%, Train Acc5: 61.6% | Val Loss: 8.16e+07, Val Acc10: 67.7%, Val Acc5: 39.7%\n",
      "Epoch [8/10] Train Loss: 1.09e+07, Train Acc10: 90.8%, Train Acc5: 62.1% | Val Loss: 8.16e+07, Val Acc10: 68.1%, Val Acc5: 39.7%\n",
      "Epoch [9/10] Train Loss: 1.09e+07, Train Acc10: 90.7%, Train Acc5: 62.0% | Val Loss: 8.15e+07, Val Acc10: 68.1%, Val Acc5: 40.1%\n",
      "Epoch [10/10] Train Loss: 1.08e+07, Train Acc10: 90.9%, Train Acc5: 62.4% | Val Loss: 8.16e+07, Val Acc10: 67.7%, Val Acc5: 39.5%\n",
      "\n",
      "kernel_size : [5, 30, 5] | out_channels : 32  | fc_features : 1024 | loss func : custom\n",
      "Epoch [1/10] Train Loss: 3.58e+03, Train Acc10: 71.9%, Train Acc5: 42.1% | Val Loss: 7.40e+03, Val Acc10: 64.3%, Val Acc5: 37.7%\n",
      "Epoch [2/10] Train Loss: nan, Train Acc10: 20.2%, Train Acc5: 12.5% | Val Loss: nan, Val Acc10: 0.0%, Val Acc5: 0.0%\n",
      "Epoch [3/10] Train Loss: nan, Train Acc10: 0.0%, Train Acc5: 0.0% | Val Loss: nan, Val Acc10: 0.0%, Val Acc5: 0.0%\n",
      "Epoch [4/10] Train Loss: nan, Train Acc10: 0.0%, Train Acc5: 0.0% | Val Loss: nan, Val Acc10: 0.0%, Val Acc5: 0.0%\n",
      "Epoch [5/10] Train Loss: nan, Train Acc10: 0.0%, Train Acc5: 0.0% | Val Loss: nan, Val Acc10: 0.0%, Val Acc5: 0.0%\n",
      "Epoch [6/10] Train Loss: nan, Train Acc10: 0.0%, Train Acc5: 0.0% | Val Loss: nan, Val Acc10: 0.0%, Val Acc5: 0.0%\n",
      "Epoch [7/10] Train Loss: nan, Train Acc10: 0.0%, Train Acc5: 0.0% | Val Loss: nan, Val Acc10: 0.0%, Val Acc5: 0.0%\n",
      "Epoch [8/10] Train Loss: nan, Train Acc10: 0.0%, Train Acc5: 0.0% | Val Loss: nan, Val Acc10: 0.0%, Val Acc5: 0.0%\n",
      "Epoch [9/10] Train Loss: nan, Train Acc10: 0.0%, Train Acc5: 0.0% | Val Loss: nan, Val Acc10: 0.0%, Val Acc5: 0.0%\n",
      "Epoch [10/10] Train Loss: nan, Train Acc10: 0.0%, Train Acc5: 0.0% | Val Loss: nan, Val Acc10: 0.0%, Val Acc5: 0.0%\n",
      "\n",
      "kernel_size : [5, 30, 5] | out_channels : 32  | fc_features : 2048 | loss func : l1\n",
      "Epoch [1/10] Train Loss: 1.19e+07, Train Acc10: 81.6%, Train Acc5: 50.8% | Val Loss: 8.15e+07, Val Acc10: 69.8%, Val Acc5: 42.1%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10] Train Loss: 1.13e+07, Train Acc10: 87.1%, Train Acc5: 56.2% | Val Loss: 8.16e+07, Val Acc10: 68.2%, Val Acc5: 40.0%\n",
      "Epoch [3/10] Train Loss: 1.12e+07, Train Acc10: 88.3%, Train Acc5: 57.9% | Val Loss: 8.16e+07, Val Acc10: 67.4%, Val Acc5: 38.6%\n",
      "Epoch [4/10] Train Loss: 1.10e+07, Train Acc10: 89.8%, Train Acc5: 60.3% | Val Loss: 8.15e+07, Val Acc10: 69.3%, Val Acc5: 41.3%\n",
      "Epoch [5/10] Train Loss: 1.10e+07, Train Acc10: 90.0%, Train Acc5: 60.2% | Val Loss: 8.16e+07, Val Acc10: 68.3%, Val Acc5: 39.7%\n",
      "Epoch [6/10] Train Loss: 1.09e+07, Train Acc10: 90.4%, Train Acc5: 61.0% | Val Loss: 8.15e+07, Val Acc10: 68.7%, Val Acc5: 40.1%\n",
      "Epoch [7/10] Train Loss: 1.09e+07, Train Acc10: 90.4%, Train Acc5: 61.4% | Val Loss: 8.15e+07, Val Acc10: 69.1%, Val Acc5: 40.4%\n",
      "Epoch [8/10] Train Loss: 1.09e+07, Train Acc10: 90.6%, Train Acc5: 62.2% | Val Loss: 8.15e+07, Val Acc10: 68.7%, Val Acc5: 40.1%\n",
      "Epoch [9/10] Train Loss: 1.08e+07, Train Acc10: 90.9%, Train Acc5: 62.4% | Val Loss: 8.15e+07, Val Acc10: 68.9%, Val Acc5: 40.2%\n",
      "Epoch [10/10] Train Loss: 1.08e+07, Train Acc10: 91.0%, Train Acc5: 62.4% | Val Loss: 8.15e+07, Val Acc10: 68.6%, Val Acc5: 39.8%\n",
      "\n",
      "kernel_size : [5, 30, 5] | out_channels : 32  | fc_features : 2048 | loss func : custom\n",
      "Epoch [1/10] Train Loss: 3.54e+03, Train Acc10: 73.3%, Train Acc5: 43.3% | Val Loss: 7.48e+03, Val Acc10: 62.2%, Val Acc5: 36.0%\n",
      "Epoch [2/10] Train Loss: 3.17e+03, Train Acc10: 83.8%, Train Acc5: 52.7% | Val Loss: 7.35e+03, Val Acc10: 65.7%, Val Acc5: 39.0%\n",
      "Epoch [3/10] Train Loss: 3.11e+03, Train Acc10: 85.8%, Train Acc5: 54.0% | Val Loss: 7.29e+03, Val Acc10: 67.8%, Val Acc5: 40.5%\n",
      "Epoch [4/10] Train Loss: 3.08e+03, Train Acc10: 86.5%, Train Acc5: 55.6% | Val Loss: 7.32e+03, Val Acc10: 66.8%, Val Acc5: 39.5%\n",
      "Epoch [5/10] Train Loss: 3.07e+03, Train Acc10: 87.0%, Train Acc5: 55.9% | Val Loss: 7.34e+03, Val Acc10: 66.4%, Val Acc5: 38.5%\n",
      "Epoch [6/10] Train Loss: 3.03e+03, Train Acc10: 87.5%, Train Acc5: 57.4% | Val Loss: 7.26e+03, Val Acc10: 68.7%, Val Acc5: 41.4%\n",
      "Epoch [7/10] Train Loss: 3.00e+03, Train Acc10: 88.1%, Train Acc5: 58.4% | Val Loss: 7.29e+03, Val Acc10: 67.8%, Val Acc5: 40.5%\n",
      "Epoch [8/10] Train Loss: 2.97e+03, Train Acc10: 88.9%, Train Acc5: 59.3% | Val Loss: 7.27e+03, Val Acc10: 68.2%, Val Acc5: 41.2%\n",
      "Epoch [9/10] Train Loss: 2.98e+03, Train Acc10: 88.9%, Train Acc5: 59.3% | Val Loss: 7.29e+03, Val Acc10: 67.7%, Val Acc5: 40.1%\n",
      "Epoch [10/10] Train Loss: 2.95e+03, Train Acc10: 89.4%, Train Acc5: 60.1% | Val Loss: 7.27e+03, Val Acc10: 68.2%, Val Acc5: 41.0%\n",
      "\n",
      "kernel_size : [5, 50, 5] | out_channels : 32  | fc_features : 1024 | loss func : l1\n",
      "Epoch [1/10] Train Loss: 1.22e+07, Train Acc10: 78.8%, Train Acc5: 49.5% | Val Loss: 8.16e+07, Val Acc10: 68.4%, Val Acc5: 40.9%\n",
      "Epoch [2/10] Train Loss: 1.10e+07, Train Acc10: 89.5%, Train Acc5: 59.9% | Val Loss: 8.16e+07, Val Acc10: 67.0%, Val Acc5: 38.5%\n",
      "Epoch [3/10] Train Loss: 1.10e+07, Train Acc10: 89.9%, Train Acc5: 60.5% | Val Loss: 8.16e+07, Val Acc10: 67.8%, Val Acc5: 39.6%\n",
      "Epoch [4/10] Train Loss: 1.09e+07, Train Acc10: 90.3%, Train Acc5: 61.1% | Val Loss: 8.16e+07, Val Acc10: 67.3%, Val Acc5: 38.6%\n",
      "Epoch [5/10] Train Loss: 1.09e+07, Train Acc10: 90.3%, Train Acc5: 61.2% | Val Loss: 8.16e+07, Val Acc10: 67.5%, Val Acc5: 38.6%\n",
      "Epoch [6/10] Train Loss: 1.09e+07, Train Acc10: 90.7%, Train Acc5: 61.9% | Val Loss: 8.15e+07, Val Acc10: 68.4%, Val Acc5: 39.9%\n",
      "Epoch [7/10] Train Loss: 1.08e+07, Train Acc10: 90.9%, Train Acc5: 62.4% | Val Loss: 8.15e+07, Val Acc10: 68.5%, Val Acc5: 40.0%\n",
      "Epoch [8/10] Train Loss: 1.08e+07, Train Acc10: 90.9%, Train Acc5: 62.3% | Val Loss: 8.16e+07, Val Acc10: 68.1%, Val Acc5: 39.3%\n",
      "Epoch [9/10] Train Loss: 1.09e+07, Train Acc10: 90.8%, Train Acc5: 62.2% | Val Loss: 8.15e+07, Val Acc10: 68.3%, Val Acc5: 39.7%\n",
      "Epoch [10/10] Train Loss: 1.08e+07, Train Acc10: 91.1%, Train Acc5: 63.1% | Val Loss: 8.15e+07, Val Acc10: 68.7%, Val Acc5: 40.2%\n",
      "\n",
      "kernel_size : [5, 50, 5] | out_channels : 32  | fc_features : 1024 | loss func : custom\n",
      "Epoch [1/10] Train Loss: 3.68e+03, Train Acc10: 69.1%, Train Acc5: 39.5% | Val Loss: 7.56e+03, Val Acc10: 59.9%, Val Acc5: 34.2%\n",
      "Epoch [2/10] Train Loss: 3.18e+03, Train Acc10: 83.4%, Train Acc5: 52.6% | Val Loss: 7.34e+03, Val Acc10: 66.0%, Val Acc5: 39.0%\n",
      "Epoch [3/10] Train Loss: 3.07e+03, Train Acc10: 86.3%, Train Acc5: 56.1% | Val Loss: 7.32e+03, Val Acc10: 66.5%, Val Acc5: 39.8%\n",
      "Epoch [4/10] Train Loss: 3.02e+03, Train Acc10: 87.8%, Train Acc5: 58.0% | Val Loss: 7.31e+03, Val Acc10: 66.9%, Val Acc5: 40.1%\n",
      "Epoch [5/10] Train Loss: 3.00e+03, Train Acc10: 88.3%, Train Acc5: 58.5% | Val Loss: 7.29e+03, Val Acc10: 67.5%, Val Acc5: 41.1%\n",
      "Epoch [6/10] Train Loss: 3.00e+03, Train Acc10: 88.4%, Train Acc5: 58.4% | Val Loss: 7.27e+03, Val Acc10: 68.5%, Val Acc5: 41.4%\n",
      "Epoch [7/10] Train Loss: 2.97e+03, Train Acc10: 89.0%, Train Acc5: 59.6% | Val Loss: 7.29e+03, Val Acc10: 67.4%, Val Acc5: 40.7%\n",
      "Epoch [8/10] Train Loss: 2.98e+03, Train Acc10: 88.6%, Train Acc5: 58.9% | Val Loss: 7.28e+03, Val Acc10: 67.7%, Val Acc5: 40.8%\n",
      "Epoch [9/10] Train Loss: 2.97e+03, Train Acc10: 89.1%, Train Acc5: 59.4% | Val Loss: 7.77e+03, Val Acc10: 54.8%, Val Acc5: 30.7%\n",
      "Epoch [10/10] Train Loss: 3.02e+03, Train Acc10: 87.5%, Train Acc5: 57.9% | Val Loss: 7.27e+03, Val Acc10: 68.2%, Val Acc5: 41.2%\n",
      "\n",
      "kernel_size : [5, 50, 5] | out_channels : 32  | fc_features : 2048 | loss func : l1\n",
      "Epoch [1/10] Train Loss: 1.20e+07, Train Acc10: 80.1%, Train Acc5: 50.3% | Val Loss: 8.18e+07, Val Acc10: 67.5%, Val Acc5: 40.4%\n",
      "Epoch [2/10] Train Loss: 1.11e+07, Train Acc10: 88.7%, Train Acc5: 58.4% | Val Loss: 8.16e+07, Val Acc10: 68.9%, Val Acc5: 41.6%\n",
      "Epoch [3/10] Train Loss: 1.11e+07, Train Acc10: 88.9%, Train Acc5: 58.6% | Val Loss: 8.15e+07, Val Acc10: 68.5%, Val Acc5: 40.5%\n",
      "Epoch [4/10] Train Loss: 1.11e+07, Train Acc10: 89.0%, Train Acc5: 59.1% | Val Loss: 8.15e+07, Val Acc10: 68.8%, Val Acc5: 40.6%\n",
      "Epoch [5/10] Train Loss: 1.10e+07, Train Acc10: 90.0%, Train Acc5: 60.4% | Val Loss: 8.15e+07, Val Acc10: 68.5%, Val Acc5: 40.4%\n",
      "Epoch [6/10] Train Loss: 1.09e+07, Train Acc10: 90.2%, Train Acc5: 61.1% | Val Loss: 8.15e+07, Val Acc10: 69.7%, Val Acc5: 41.8%\n",
      "Epoch [7/10] Train Loss: 1.09e+07, Train Acc10: 90.9%, Train Acc5: 62.2% | Val Loss: 8.15e+07, Val Acc10: 69.4%, Val Acc5: 41.3%\n",
      "Epoch [8/10] Train Loss: 1.09e+07, Train Acc10: 90.8%, Train Acc5: 62.0% | Val Loss: 8.15e+07, Val Acc10: 69.5%, Val Acc5: 41.6%\n",
      "Epoch [9/10] Train Loss: 1.09e+07, Train Acc10: 90.7%, Train Acc5: 62.0% | Val Loss: 8.15e+07, Val Acc10: 69.1%, Val Acc5: 40.8%\n",
      "Epoch [10/10] Train Loss: 1.08e+07, Train Acc10: 90.9%, Train Acc5: 62.3% | Val Loss: 8.15e+07, Val Acc10: 69.0%, Val Acc5: 40.8%\n",
      "\n",
      "kernel_size : [5, 50, 5] | out_channels : 32  | fc_features : 2048 | loss func : custom\n",
      "Epoch [1/10] Train Loss: 3.61e+03, Train Acc10: 71.1%, Train Acc5: 41.1% | Val Loss: 7.43e+03, Val Acc10: 63.5%, Val Acc5: 36.6%\n",
      "Epoch [2/10] Train Loss: 3.17e+03, Train Acc10: 84.0%, Train Acc5: 52.6% | Val Loss: 7.41e+03, Val Acc10: 64.3%, Val Acc5: 37.5%\n",
      "Epoch [3/10] Train Loss: 3.10e+03, Train Acc10: 85.7%, Train Acc5: 55.2% | Val Loss: 7.38e+03, Val Acc10: 65.0%, Val Acc5: 38.2%\n",
      "Epoch [4/10] Train Loss: 3.04e+03, Train Acc10: 87.3%, Train Acc5: 56.9% | Val Loss: 7.35e+03, Val Acc10: 65.9%, Val Acc5: 39.4%\n",
      "Epoch [5/10] Train Loss: 3.06e+03, Train Acc10: 86.9%, Train Acc5: 56.1% | Val Loss: 7.31e+03, Val Acc10: 67.0%, Val Acc5: 40.1%\n",
      "Epoch [6/10] Train Loss: 2.99e+03, Train Acc10: 88.6%, Train Acc5: 58.9% | Val Loss: 7.29e+03, Val Acc10: 67.4%, Val Acc5: 40.6%\n",
      "Epoch [7/10] Train Loss: 3.03e+03, Train Acc10: 87.5%, Train Acc5: 57.7% | Val Loss: 7.30e+03, Val Acc10: 67.3%, Val Acc5: 40.2%\n",
      "Epoch [8/10] Train Loss: 3.00e+03, Train Acc10: 88.2%, Train Acc5: 58.7% | Val Loss: 7.33e+03, Val Acc10: 66.3%, Val Acc5: 39.2%\n",
      "Epoch [9/10] Train Loss: 2.95e+03, Train Acc10: 89.3%, Train Acc5: 60.1% | Val Loss: 7.28e+03, Val Acc10: 67.9%, Val Acc5: 40.8%\n",
      "Epoch [10/10] Train Loss: 3.00e+03, Train Acc10: 88.4%, Train Acc5: 58.2% | Val Loss: 7.30e+03, Val Acc10: 67.1%, Val Acc5: 40.1%\n"
     ]
    }
   ],
   "source": [
    "for i, kernel_size in enumerate(kernel_size_list):\n",
    "    for j, out_channels in enumerate(out_channels_list):\n",
    "        for k, fc_features in enumerate(fc_features_list):\n",
    "            for l, padding in enumerate(padding_list):\n",
    "                for m, loss_function in enumerate(loss_function_list):\n",
    "                    #print((i+1)*(j+1)*(k+1), '/', len(kernel_size_list)*len(out_channels_list)*len(fc_features_list), '\\r', end='')\n",
    "                    print('\\nkernel_size :', kernel_size, '| out_channels :', out_channels, ' | fc_features :', fc_features, \\\n",
    "                          '| loss func :', loss_function)\n",
    "                    try: \n",
    "                        del(model)\n",
    "                    except NameError:\n",
    "                        pass\n",
    "                    gc.collect()\n",
    "                    torch.cuda.empty_cache()\n",
    "\n",
    "                    model = Model(batch_size=25, n_conv=2, out_channels=out_channels, kernel_size=kernel_size, stride=2, padding=1,\\\n",
    "                                  fc_features=fc_features)\n",
    "\n",
    "                    out = train(model, train_loader, val_loader, num_epochs=10, batch_size=25, out=True, test_mode=True, \\\n",
    "                                loss_function=loss_function)\n",
    "                    with open('hyperparameter_results.txt', 'a') as f:\n",
    "                        f.write(\"Train Loss: {:.2e}, Train Acc10: {:.1f}%, Train Acc5: {:.1f}% | \\\n",
    "    Val Loss: {:.2e}, Val Acc10: {:.1f}%, Val Acc5: {:.1f}%\\n\".format(out[0], out[1], out[2], out[3], out[4], out[5]))\n",
    "                    f.close()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "98f39613",
   "metadata": {},
   "source": [
    "Top 5 performing on validation, 5 degrees: \n",
    "\n",
    "[5, 10, 5], 32, 2048, l1\n",
    "[5, 10, 5], 32, 1024, l1\n",
    "[3, 10, 3], 32, 2048, custom\n",
    "[3, 30, 3], 32, 1024, custom\n",
    "[5, 10, 5], 32, 1024, custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "e8ea87f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Free: 3.2%\n",
      "Total: 251.65G\n",
      "Used: 7.12G\n",
      "Used - Start: 2.99G\n"
     ]
    }
   ],
   "source": [
    "mem_usage = psutil.virtual_memory()\n",
    "\n",
    "print(f\"Free: {mem_usage.percent}%\")\n",
    "print(f\"Total: {mem_usage.total/(1024**3):.2f}G\")\n",
    "print(f\"Used: {mem_usage.used/(1024**3):.2f}G\")\n",
    "print(f\"Used - Start: {(mem_usage.used - mem_usage_start)/(1024**3):.2f}G\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3ed5b4",
   "metadata": {},
   "source": [
    "# Step 6. Run [what I think might be] the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7277be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on file 45 / 461 \r"
     ]
    }
   ],
   "source": [
    "model = Model(batch_size=25, n_conv=2, out_channels=64, kernel_size=(5, 10, 5), stride=2, padding='circular', fc_features=2048)\n",
    "\n",
    "train(model, train_loader, val_loader, num_epochs=20, batch_size=25, test_mode=False, loss_function='custom')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0254853f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
